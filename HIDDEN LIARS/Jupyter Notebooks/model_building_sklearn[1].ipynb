{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54e73bc8",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0c41f7",
   "metadata": {},
   "source": [
    "### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7d8186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d59690c",
   "metadata": {},
   "source": [
    "### 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bb3c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data\n",
    "df = pd.read_csv(\"tomato_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292f6d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f54a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and prepare the necessary data by dropping irrelevant columns\n",
    "cols_to_drop = [\"id_soil\", \"device_identifier_soil\", \"line\", \"id_env\", \"device_identifier_env\"]\n",
    "df = df.drop(cols_to_drop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb354b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5950909",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename columns\n",
    "df.rename(columns={\n",
    "    'humidity_soil': 'soil_moisture',\n",
    "    'temperature_soil': 'soil_temperature',\n",
    "    'humidity_env': 'env_humidity',\n",
    "    'temperature_env': 'env_temperature',\n",
    "    'time': 'hourly_time',\n",
    "    'sum_rain': 'precipitations_mm',\n",
    "    'mean_humidity': 'humidity',\n",
    "    'mean_et0_fao': 'et0_fao',\n",
    "    'irrigation_label': 'irrigation_status'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf5a534",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd97276",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data without time labels\n",
    "data = df.drop(['ts_generation', 'hourly_time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d95bde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad03cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the target column (irrigation_status)\n",
    "label_encoder = LabelEncoder()\n",
    "data['irrigation_status'] = label_encoder.fit_transform(data['irrigation_status'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8073b359",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91480f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = data.drop('irrigation_status', axis=1).values\n",
    "y = data['irrigation_status'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d764561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13690ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a711f3",
   "metadata": {},
   "source": [
    "### 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114b39fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "model = MLPClassifier(random_state=42, max_iter=500)\n",
    "\n",
    "# Define the parameter grid for Grid Search\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(64, 32), (128, 64), (64,), (128,)],  # Different layer configurations\n",
    "    'activation': ['relu', 'tanh'],  # Activation functions to test\n",
    "    'solver': ['adam', 'sgd'],       # Solvers to test\n",
    "    'alpha': [0.0001, 0.001, 0.01], # Regularization parameter\n",
    "    'learning_rate': ['constant', 'adaptive']  # Learning rate strategies\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',  # Use appropriate scoring metric for your task\n",
    "    cv=3,                # 3-fold cross-validation\n",
    "    verbose=3            # Verbosity for progress updates\n",
    ")\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "# Evaluate on test set (optional)\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90a2c7f",
   "metadata": {},
   "source": [
    "### 4. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d75b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469c8b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the scaler, model, and label encoder\n",
    "joblib.dump(scaler, 'StandardScaler_2.joblib')\n",
    "joblib.dump(model, 'mlp_model.joblib')\n",
    "joblib.dump(label_encoder, 'label_encoder_2.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032855a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict a single row\n",
    "def prepare_single_row_for_prediction(features_array, model, scaler, label_encoder):\n",
    "    # Scale the features\n",
    "    sample_row_scaled = scaler.transform([features_array])\n",
    "\n",
    "    # Predict using the neural network model\n",
    "    prediction = model.predict(sample_row_scaled)\n",
    "\n",
    "    # Decode the predicted class using the label encoder\n",
    "    predicted_class = label_encoder.inverse_transform(prediction)\n",
    "    print(predicted_class)\n",
    "    \n",
    "    return predicted_class[0]\n",
    "\n",
    "# Example usage\n",
    "sample_row = np.array([723.0, 31.90, 29.0, 31.5, 35.9, 23.1, 85.222222, 0.144306])  # Replace with actual features\n",
    "predicted_class = prepare_single_row_for_prediction(sample_row, model, scaler, label_encoder)\n",
    "print(f\"Predicted class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebcb675",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_mapping = {index: label for index, label in enumerate(label_encoder.classes_)}\n",
    "print(\"Label Mapping (Encoded Value -> Class Name):\")\n",
    "for encoded_value, class_name in label_mapping.items():\n",
    "    print(f\"{encoded_value}: {class_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
